#!/usr/bin/env npx tsx
/**
 * Test the complete Latin content generation workflow
 * This tests the full stack: API route â†’ workflow â†’ language factory â†’ Latin processor
 */

async function testLatinContentGeneration() {
  console.log('ğŸ›ï¸ Testing Complete Latin Content Generation Workflow\n')

  const testData = {
    lessonId: 'test-lesson-123',
    readingText: 'Marcus in via ambulat et rosam pulchram videt dum ad forum festinat. Puella in horto flores legit.',
    targetLevel: 'A1',
    language: 'la',
    maxVocabularyItems: 10,
    userId: 'test-user-456'
  }

  try {
    console.log('ğŸ“¤ Simulating API request...')
    console.log(`   ğŸ“š Text: "${testData.readingText.substring(0, 50)}..."`)
    console.log(`   ğŸ¯ Level: ${testData.targetLevel}`)
    console.log(`   ğŸ›ï¸ Language: ${testData.language}`)
    console.log(`   ğŸ“Š Max items: ${testData.maxVocabularyItems}\n`)

    // Import the workflow function directly (simulating the API route)
    const { executeContentGeneration, contentGenerationInputSchema } = await import('../lib/content-generation/workflows/content-generation')

    // Validate input (same as API route does)
    const validationResult = contentGenerationInputSchema.safeParse(testData)

    if (!validationResult.success) {
      console.error('âŒ Input validation failed:')
      console.error(validationResult.error.format())
      return
    }

    console.log('âœ… Input validation passed')

    // Execute the workflow
    console.log('\nğŸš€ Executing content generation workflow...')
    const startTime = Date.now()

    const result = await executeContentGeneration(validationResult.data)

    const totalTime = Date.now() - startTime

    console.log('\nğŸ“Š Results:')
    console.log(`   ğŸ“ˆ Status: ${result.status}`)
    console.log(`   ğŸ“ Vocabulary count: ${result.metadata.vocabularyCount}`)
    console.log(`   â±ï¸  Execution time: ${result.metadata.executionTime}ms (total: ${totalTime}ms)`)
    console.log(`   ğŸ’° Estimated cost: $${result.metadata.cost}`)
    console.log(`   ğŸ”§ Processor type: ${result.metadata.processorType}`)

    if (result.vocabulary && result.vocabulary.length > 0) {
      console.log('\nğŸ“š Generated Vocabulary:')
      result.vocabulary.slice(0, 5).forEach((word, i) => {
        console.log(`   ${i + 1}. ${word}`)
      })
      if (result.vocabulary.length > 5) {
        console.log(`   ... and ${result.vocabulary.length - 5} more`)
      }
    }

    if (result.metadata.vocabularyDetails) {
      console.log('\nğŸ” Detailed Vocabulary (first 3):')
      result.metadata.vocabularyDetails.slice(0, 3).forEach((item, i) => {
        console.log(`   ${i + 1}. ${item.word} â†’ ${item.definition}`)
        if (item.partOfSpeech) console.log(`      ğŸ“ Part of speech: ${item.partOfSpeech}`)
        if (item.lemma) console.log(`      ğŸ”— Lemma: ${item.lemma}`)
      })
    }

    if (result.status === 'completed') {
      console.log('\nğŸ‰ Latin content generation workflow completed successfully!')
      console.log('\nğŸ’¡ Next steps:')
      console.log('   â€¢ Add OPENAI_API_KEY for real LLM processing')
      console.log('   â€¢ Test with longer Latin texts')
      console.log('   â€¢ Test the UI integration with Latin lesson creation')
    } else {
      console.log('\nâš ï¸ Workflow completed with issues:')
      if (result.metadata.error) {
        console.log(`   Error: ${result.metadata.error}`)
      }
    }

  } catch (error) {
    console.error('\nâŒ Test failed:')
    console.error(error instanceof Error ? error.message : error)

    if (error instanceof Error && error.stack) {
      console.log('\nğŸ” Stack trace:')
      console.log(error.stack)
    }
  }
}

// Run test if executed directly
if (require.main === module) {
  testLatinContentGeneration()
}

export { testLatinContentGeneration }